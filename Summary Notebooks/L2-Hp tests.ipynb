{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One sided test on known distr\n",
    "\n",
    "# Input data distr info\n",
    "mu = 75.5       # Mean \n",
    "sigma = 3.5     # Standard deviation\n",
    "n = 6          # Number of samples\n",
    "\n",
    "mu0 = 75.75    # Hypothesized mean\n",
    "\n",
    "prob = 1 - stats.norm.cdf(mu0, mu, sigma/np.sqrt(n))\n",
    "print('The probability of observing a sample mean larger than mu0 is: %.3f' % prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on diff between two distr \n",
    "\n",
    "# Input data\n",
    "n1 = 16          # Number of samples\n",
    "mu1 = 75         # Mean\n",
    "sigma1 = 8       # Standard deviation\n",
    "\n",
    "n2 = 9           # Number of samples\n",
    "mu2 = 70         # Mean\n",
    "sigma2 = 12      # Standard deviation\n",
    "\n",
    "# Compute the mean and the variance of the difference between the two populations\n",
    "mu_diff = mu1 - mu2 \n",
    "sigma_diff = np.sqrt(sigma1**2/n1 + sigma2**2/n2)   # the operator ** stands for ^ (i.e., power of)\n",
    "\n",
    "mu0 = 4       # Difference between the means\n",
    "\n",
    "# P(X1 - X2 > mu0) = P(Z > (mu0 - mu_diff)/sigma_diff)\n",
    "prob = 1 - stats.norm.cdf((mu0 - mu_diff)/sigma_diff)\n",
    "\n",
    "print('Probability of the difference between the means being greater than %.1f is %.4f' % (mu0, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of difference in range\n",
    "\n",
    "lower_bound = 3.5      # Lower bound of the interval\n",
    "upper_bound = 5.5      # Upper bound of the interval\n",
    "\n",
    "# P(lower_bound < X1 - X2 < upper_bound) = P(X1 - X2 < upper_bound) - P(X1 - X2 < lower_bound)\n",
    "prob = stats.norm.cdf((upper_bound - mu_diff)/sigma_diff) - stats.norm.cdf((lower_bound - mu_diff)/sigma_diff)\n",
    "\n",
    "print('Probability of the difference between the means being between %.1f and %.1f is %.4f' % (lower_bound, upper_bound, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two sided \n",
    "#if one sided use alpha instead of alpha/2\n",
    "\n",
    "mu0 = 10   #mean of null hypothesis\n",
    "# Calculate the Z-statistic\n",
    "Z_0 = (np.mean(x1) - mu0) / (sigma / np.sqrt(n))\n",
    "\n",
    "print('Test statistic Z_0 = %.3f' % Z_0)\n",
    "\n",
    "# Compare the Z-statistic with the critical value\n",
    "alpha = 0.05   # significance level\n",
    "z_alpha2 = stats.norm.ppf(1-alpha/2)    #remind: inverse cumulative distribution function \n",
    "\n",
    "if np.abs(Z_0) > z_alpha2:\n",
    "    print('Reject the null hypothesis at alpha = %.2f' % alpha)\n",
    "else:\n",
    "    print('Accept the null hypothesis at alpha = %.2f' % alpha)\n",
    "\n",
    "# Compute confidence interval manually\n",
    "#CI = [np.mean(x1) - z_alpha2 * sigma/np.sqrt(n), np.mean(x1) + z_alpha2 * sigma/np.sqrt(n)]\n",
    "\n",
    "CI = stats.norm.interval(1-alpha, loc=np.mean(x1), scale=sigma/np.sqrt(n))\n",
    "print('Confidence interval: %.3f, %.3f' % (CI[0],CI[1]))\n",
    "\n",
    "pval = 2 * ( 1 - stats.norm.cdf(np.abs(Z_0)) )      #attention: bilateral rejection region\n",
    "print('p-value = %.3f' % pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power curve of the test\n",
    "delta = np.linspace(0, 30, 100)\n",
    "mu1 = mu0 + delta\n",
    "Z_alpha2 = stats.norm.ppf(1 - alpha / 2)\n",
    "\n",
    "# Compute the power curves for n = 20 and n = 40\n",
    "n = 20\n",
    "power_20 = 1 - stats.norm.cdf(Z_alpha2 - delta * np.sqrt(n) / sigma) + stats.norm.cdf(-Z_alpha2 - delta * np.sqrt(n) / sigma)\n",
    "n = 40\n",
    "power_40 = 1 - stats.norm.cdf(Z_alpha2 - delta * np.sqrt(n) / sigma) + stats.norm.cdf(-Z_alpha2 - delta * np.sqrt(n) / sigma)\n",
    "\n",
    "\n",
    "# Plot the power curve\n",
    "plt.plot(delta, power_20, label = \"power (n = 20)\")\n",
    "plt.plot(delta, power_40, label = \"power (n = 40)\")\n",
    "plt.xlabel(\"delta\")\n",
    "plt.ylabel(\"power\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two sided on data x1\n",
    "\n",
    "mu = 10     # mean\n",
    "sigma = 1   # standard deviation\n",
    "n = 40    # sample size\n",
    "\n",
    "mu0 = 10    #null hypothesis\n",
    "# Calculate the t-statistic\n",
    "t_0 = (np.mean(x1) - mu0) / (np.std(x1, ddof=1) / np.sqrt(n))\n",
    "\n",
    "# Compare the t-statistic with the critical value\n",
    "alpha = 0.05   # significance level\n",
    "t_alpha = stats.t.ppf(1-alpha/2, n-1)\n",
    "\n",
    "if t_0 > t_alpha:\n",
    "    print('Reject the null hypothesis at alpha = %.2f' % alpha)\n",
    "else:\n",
    "    print('Accept the null hypothesis at alpha = %.2f' % alpha)\n",
    "\n",
    "CI_b = [data[''].mean() - t_alpha * data[''].std() / np.sqrt(n),\n",
    "        data[''].mean() + t_alpha * data[''].std() / np.sqrt(n)]\n",
    "print('Two-sided confidence interval (%.2f): [%.3f, %.3f]' % (1-alpha, CI_b[0], CI_b[1]))\n",
    "\n",
    "pval = 1 - stats.t.cdf(t_0,n-1)\n",
    "print('p-value = %.3f' % pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or with command to make t-test\n",
    "t_0, pval = stats.ttest_1samp(x1, mu0, alternative='two-sided')  #or alternative = greater, or less\n",
    "print('Test statistic t_0 = %.3f' % t_0)\n",
    "print('p-value = %.3f' % pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or with command for conf interval\n",
    "CI = stats.t.interval(1-alpha, n-1, loc=data[''].mean(), scale=data[''].std() / np.sqrt(n))\n",
    "print('Confidence interval: (%.3f, %.3f)' % (CI[0], CI[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-sided confidence interval lower bound \n",
    "df = n - 1     # Degrees of freedom\n",
    "t_alpha = stats.t.ppf(1 - alpha, df)\n",
    "CI_lower = data[''].mean() - t_alpha * data[''].std() / np.sqrt(n)\n",
    "print('Lower bound of the one-sided confidence interval: %.3f' % CI_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the confidence interval on a dot plot\n",
    "plt.title('One-sided confidence interval for the mean with CL = %.2f' % CL)\n",
    "plt.scatter(data[''], np.zeros(n), label='')\n",
    "# plot the confidence interval\n",
    "plt.scatter(CI_b[0], -0.01, color='r', marker='|', s=100)\n",
    "plt.scatter(CI_b[1], -0.01, color='r', marker='|', s=100)\n",
    "plt.plot([CI_b[0], CI_b[1]], [-0.01, -0.01], color='r', label='C.I.')\n",
    "# Add labels and legend\n",
    "plt.ylim(-0.03, 0.03)\n",
    "plt.xlabel('')\n",
    "plt.yticks([])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired t-test \n",
    "t0_stats_trel, p_value_t0_stats_trel = stats.ttest_rel(data['before'], data['after'], alternative='greater')\n",
    "print('t-statistic from stats.ttest_rel: %.3f' % t0_stats_trel)\n",
    "print('p-value from stats.ttest_rel: %.3f' % p_value_t0_stats_trel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "CL = 0.95       # Confidence level\n",
    "alpha = 1 - CL  # Significance level\n",
    "n = len(data)   # Sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  One-sided CI on the variance\n",
    "df = n - 1      # Degrees of freedom\n",
    "chi2 = stats.chi2.ppf(alpha, df)\n",
    "CI_upper = df * data[''].var() / chi2\n",
    "print('Upper bound of the one-sided CI on the variance: %.3f' % CI_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-sided CI on the variance\n",
    "chi2_1 = stats.chi2.ppf(alpha / 2, df)\n",
    "chi2_2 = stats.chi2.ppf(1 - alpha / 2, df)\n",
    "\n",
    "CI_var = [df * data[''].var() / chi2_2,\n",
    "        df * data[''].var() / chi2_1]\n",
    "\n",
    "CI_stdev_d = np.sqrt(CI_var)\n",
    "print('Two-sided CI on the standard deviation (CL = %.2f): [%.3f, %.3f]' % (CL, CI_stdev_d[0], CI_stdev_d[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis at alpha = 0.05\n",
      "p-value = 0.020\n"
     ]
    }
   ],
   "source": [
    "#  One-sided CI on the variance\n",
    "# H0:sigmares<sigma0      vs     H1: sigmares>sigma0\n",
    "\n",
    "df = n - 2      # Degrees of freedom\n",
    "chi_alpha = stats.chi2.ppf(1-alpha, df)\n",
    "chi0 = df * model.resid.var() / (sigma0**2)\n",
    "\n",
    "if chi0 > chi_alpha:\n",
    "    print('Reject the null hypothesis at alpha = %.2f' % alpha)\n",
    "else:\n",
    "    print('Accept the null hypothesis at alpha = %.2f' % alpha)\n",
    "\n",
    "pval = 1 - stats.chi2.cdf(chi0, df)\n",
    "print('p-value = %.3f' % pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normality assumption tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk test\n",
    "_, p_value_SW = stats.shapiro(data[''])\n",
    "print('p-value of the Shapiro-Wilk test: %.3f' % p_value_SW)\n",
    "# QQ-plot\n",
    "stats.probplot(data[''], dist='norm', plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anderson-Darling test\n",
    "def ADpvalue(data):\n",
    "    \"\"\"\n",
    "    This function computes the p-value of the Anderson-Darling test.\n",
    "    \n",
    "    Input:\n",
    "        data: data to be tested\n",
    "    Output:\n",
    "        p_value_AD: p-value of the Anderson-Darling test\n",
    "\n",
    "    \"\"\"\n",
    "    anderson = stats.anderson(data, dist='norm')\n",
    "    # compute the p-value of the Anderson-Darling test\n",
    "    if anderson.statistic >= 0.6:\n",
    "        p_value_AD = np.exp(1.2937 - 5.709*anderson.statistic + 0.0186*(anderson.statistic**2))\n",
    "    elif anderson.statistic >= 0.34:\n",
    "        p_value_AD = np.exp(0.9177 - 4.279*anderson.statistic - 1.38*(anderson.statistic**2))\n",
    "    elif anderson.statistic >= 0.2:\n",
    "        p_value_AD = 1 - np.exp(-8.318 + 42.796*anderson.statistic - 59.938*(anderson.statistic**2))\n",
    "    else:\n",
    "        p_value_AD = 1 - np.exp(-13.436 + 101.14*anderson.statistic - 223.73*(anderson.statistic**2))\n",
    "\n",
    "    return p_value_AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_AD = ADpvalue(data[''])\n",
    "print('p-value of the Anderson-Darling test: %.3f' % p_value_AD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the equality of variances\n",
    "# F-test\n",
    "# H0: sigma1^2=sigma2^2      H1:sigma1^2!=sigma2^2\n",
    "\n",
    "F0 = data1.var()/data2.var()\n",
    "df1 = n1 - 1 # degrees of freedom for supplier 1\n",
    "df2 = n2 - 1 # degrees of freedom for supplier 2\n",
    "CI = [F0 * stats.f.ppf(alpha/2, df2, df1), F0 * stats.f.ppf(1-alpha/2, df2, df1)]\n",
    "print('Confidence interval on the ratio of variances (CL = %.2f): [%.3f, %.3f]' % (CL, CI[0], CI[1]))\n",
    "#no reason to think vars different if 1 in interval\n",
    "\n",
    "# Compute the p-value\n",
    "p_value_F0 = 2 * stats.f.cdf(F0, df1, df2)\n",
    "print('p-value for F-test for equal variances: %.3f' % p_value_F0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 95% confidence interval on the individual standard deviation\n",
    "CI_sigma_1 = np.sqrt([(df1 * data1.var())/stats.chi2.ppf(1-alpha/2, df1), (df1 * data1.var())/stats.chi2.ppf(alpha/2, df1)])\n",
    "CI_sigma_2 = np.sqrt([(df2 * data2.var())/stats.chi2.ppf(1-alpha/2, df2), (df2 * data2.var())/stats.chi2.ppf(alpha/2, df2)])\n",
    "print('Confidence interval on the standard deviation for supplier 1 (CL = %.2f): [%.3f, %.3f]' % (CL, CI_sigma_1[0], CI_sigma_1[1]))\n",
    "print('Confidence interval on the standard deviation for supplier 2 (CL = %.2f): [%.3f, %.3f]' % (CL, CI_sigma_2[0], CI_sigma_2[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0, p_value_t0 = stats.ttest_ind(data1, data2, equal_var=True,alternative='greater')\n",
    "print('t-test: t0 = %.3f' % t0)\n",
    "print('p-value for t-test: %.3f' % p_value_t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power of f test\n",
    "ratio = 1.5 # ratio between the variances of the two samples\n",
    "beta = stats.f.cdf(stats.f.ppf(1-alpha/2, df1, df2)/ratio, df1, df2) - stats.f.cdf(stats.f.ppf(alpha/2, df1, df2)/ratio, df1, df2)\n",
    "print('Power of the test: %.3f' % (1-beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d8ec47cd585a786a2efbb520d554c7d611207870f64a3a0e1d27be6f7a4b38ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
