{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of points above the mean\n",
    "m = np.sum(data > mean).values[0]\n",
    "print('Number of points above the mean, m = %d' % m) \n",
    "\n",
    "#using count function\n",
    "m = data[data > mean].count()\n",
    "print('Number of points above the mean, m = %d' % m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new series with the mean subtracted from the original series\n",
    "new_series = np.array(data - mean).flatten()\n",
    "\n",
    "# Count how many times the sign changes \n",
    "runs = (np.sum(np.diff(np.sign(new_series)) != 0) + 1)\n",
    "print('Number of runs = %d' % runs) #number of runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expected number of runs\n",
    "exp_runs= 2*m*(n-m)/n +1\n",
    "print('Expected number of runs = %.3f' % exp_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation of the number of runs\n",
    "std_runs = np.sqrt((2*m*(n-m)*(2*m*(n-m)-n)/((n**2)*(n-1))))\n",
    "print('Standard deviation of runs = %.03f' % std_runs)\n",
    "\n",
    "#95% confidence interval\n",
    "conf_int= stats.norm.interval(0.95, loc=exp_runs, scale=std_runs)\n",
    "print('Confidence interval: (%.3f, %.3f)' % (conf_int[0], conf_int[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H0: data is random\n",
    "\n",
    "alpha = 0.05 # significance level\n",
    "#test statistic\n",
    "z0 = (runs-exp_runs)/std_runs\n",
    "z0 = z0.values[0]\n",
    "print('z0 = %f' % z0)\n",
    "z_alfa2= stats.norm.ppf(1-alpha/2)\n",
    "print('z_alfa2 = %f' % z_alfa2)\n",
    "\n",
    "if abs(z0)>z_alfa2:\n",
    "  print('The null hypothesis is rejected')\n",
    "else: \n",
    "  print('The null hypothesis is accepted')\n",
    "\n",
    "\n",
    "# Remember, it is a two-tailed test, so we need to multiply the p-value by 2\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z0)))\n",
    "print('p-value = %.3f' % p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct test and pvalue through library\n",
    "\n",
    "# Import the necessary libraries for the runs test\n",
    "from statsmodels.sandbox.stats.runs import runstest_1samp\n",
    "\n",
    "stat, pval_runs = runstest_1samp(data['Ex1'], correction=False)\n",
    "print('Runs test statistic = {:.3f}'.format(stat))\n",
    "print('Runs test p-value = {:.3f}'.format(pval_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autocorrelation graph\n",
    "# acf test\n",
    "sgt.plot_acf(data['Ex2'], lags = int(len(data)/3), zero=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-Cox transformation\n",
    "\n",
    "[data_norm, lmbda] = stats.boxcox(data[''])\n",
    "#data_norm = stats.boxcox(data[''], lmbda = )\n",
    "\n",
    "print('Lambda = %.3f' % lmbda)\n",
    "\n",
    "plt.hist(data_norm)\n",
    "plt.title('Histogram of Box-Cox transformed data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bartlett's test at lag 1\n",
    "alpha = 0.05\n",
    "lag_test = 1\n",
    "rk = acf_values[lag_test]\n",
    "z_alpha2 = stats.norm.ppf(1-alpha/2)\n",
    "print('Test statistic rk = %f' % rk)\n",
    "print('Rejection region starts at %f' % (z_alpha2/np.sqrt(n)))\n",
    "\n",
    "if rk>z_alpha2/np.sqrt(n):\n",
    "    print('The null hypothesis is rejected')\n",
    "else: print('The null hypothesis is accepted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_test = 6 # this is just an example; \n",
    "\n",
    "# Generally speaking: how many lags?\n",
    "# Rule of thumb: L<sqrt(n)\n",
    "\n",
    "Q0_LBQ = lbq[lag_test-1]\n",
    "print('Q0_LBQ = %f' % Q0_LBQ)\n",
    "\n",
    "#Rejection region for chi square distribution \n",
    "dof = lag_test\n",
    "chi2_alfa= stats.chi2.ppf(1-alpha,dof)\n",
    "print('Rejection region starts at %f' % chi2_alfa)\n",
    "\n",
    "if Q0_LBQ>chi2_alfa:        \n",
    "  print('The null hypothesis is rejected')                \n",
    "else: \n",
    "  print('The null hypothesis is accepted')\n",
    "\n",
    "# Compute the p-value for the LBQ test\n",
    "pval = 1 - stats.chi2.cdf(Q0_LBQ, lag_test)\n",
    "print('p-value = %f' % pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LBQ test for autocorrelation\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "lbq_test = acorr_ljungbox(data_norm, lags=[lag_test], return_df=True)\n",
    "print('LBQ test statistic at lag %d = %f' % (lag_test, lbq_test.loc[lag_test,'lb_stat']))\n",
    "print('LBQ test p-value at lag %d = %f' % (lag_test, lbq_test.loc[lag_test,'lb_pvalue']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gapping \n",
    "gap_size= 6 # this is just an example, you can try different gapping intervals\n",
    "gap_num= int(len(data)/gap_size)\n",
    "\n",
    "gap_data= np.zeros((gap_num))\n",
    "for i in range (gap_num):\n",
    "    gap_data[i]=data['Ex3'][i*6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built in\n",
    "# Take one data point every 6\n",
    "gap_data = data['Ex3'][::gap_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching\n",
    "batch_size = 6\n",
    "batch_num = int(len(data)/batch_size)\n",
    "\n",
    "j=0\n",
    "batch_data = np.zeros((batch_num))\n",
    "for i in range (batch_num):\n",
    "    batch_data[i]=np.sum(data['Ex3'][j:j+batch_size])/batch_size\n",
    "    j=j+batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative method\n",
    "# Create a new column in the dataframe with the corresponding batch number\n",
    "data['Batch'] = np.repeat(np.arange(1, batch_num+1), batch_size)\n",
    "\n",
    "# Store the batch means in a new dataframe\n",
    "batch_data = data.groupby('Batch').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d8ec47cd585a786a2efbb520d554c7d611207870f64a3a0e1d27be6f7a4b38ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
