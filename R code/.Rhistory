geom_point(size = 5, shape = 1) +
labs(title = "Frequenza delle combinazioni Orario di Partenza - Giorno della Settimana",
x = "Orario di Partenza",
y = "Giorno della Settimana") +
scale_color_gradient(low = "green", high = "red") +  # specifica i colori per la scala di colori
theme_minimal()
ggplot(df_tabella, aes(x = Orario.Par, y = Day_of_Week, color = Frequenza)) +
geom_point(size = 5) +
labs(title = "Frequenza delle combinazioni Orario di Partenza - Giorno della Settimana",
x = "Orario di Partenza",
y = "Giorno della Settimana") +
scale_color_gradient(low = "green", high = "red") +  # specifica i colori per la scala di colori
theme_minimal()
df_tabella <- as.data.frame.table(tabella_frequenze)
df_tabella <- df_tabella[df_tabella$Freq != 0, ]
# Rinominiamo le colonne
colnames(df_tabella) <- c("Orario.Par", "Day_of_Week", "Frequenza")
# Creiamo il grafico con grandezza dei punti proporzionale ai valori nella tabella
ggplot(df_tabella, aes(x = Orario.Par, y = Day_of_Week, color = Frequenza)) +
geom_point(size = 5) +
labs(title = "Frequenza delle combinazioni Orario di Partenza - Giorno della Settimana",
x = "Orario di Partenza",
y = "Giorno della Settimana") +
scale_color_gradient(low = "green", high = "red") +  # specifica i colori per la scala di colori
theme_minimal()
palette_verde_rosso <- colorRampPalette(c("green", "red"))
# Selezioniamo i primi 4 colori della palette
palette_verde_rosso_4 <- palette_verde_rosso(4)
ggplot(df_tabella, aes(x = Orario.Par, y = Day_of_Week, color = Frequenza)) +
geom_point(size = 5) +
labs(title = "Frequenza delle combinazioni Orario di Partenza - Giorno della Settimana",
x = "Orario di Partenza",
y = "Giorno della Settimana") +
scale_color_gradient(colours = palette_verde_rosso_4) +  # specifica i colori per la scala di colori
theme_minimal()
# Creiamo il grafico con grandezza dei punti proporzionale ai valori nella tabella
ggplot(df_tabella, aes(x = Orario.Par, y = Day_of_Week, color = Frequenza)) +
geom_point(size = 5) +
labs(title = "Frequenza delle combinazioni Orario di Partenza - Giorno della Settimana",
x = "Orario di Partenza",
y = "Giorno della Settimana") +
scale_color_gradientn(colours = palette_verde_rosso_4) +  # specifica i colori per la scala di colori
theme_minimal()
ggplot(df_tabella, aes(x = Orario.Par, y = Day_of_Week, color = Frequenza)) +
geom_point(size = 5) +
labs(title = "Frequenza delle combinazioni Orario di Partenza - Giorno della Settimana",
x = "Orario di Partenza",
y = "Giorno della Settimana") +
scale_color_gradient(low = "green", high = "red") +  # specifica i colori per la scala di colori
theme_minimal()
which(cluster1.ritGRAVI$Day_of_Week == 'sabato' & cluster1.ritGRAVI$Orario.Par == hms::as_hms('13:34:00'))
cluster1.ritGRAVI[c(63,71,74,77,78), ]
k <- 3
pam_fit <- pam(CTCLE_PACLE.data[,5:7], diss = FALSE, k)
pam_results <- CTCLE_PACLE.data %>%
mutate(cluster = pam_fit$clustering) %>%
group_by(cluster) %>%
do(the_summary = summary(.))
pam_results$the_summary
View(CTCLE_PACLE.data)
# Caricamento del dataset e delle funzioni
dataset <- read.csv('../../Dataset/Facsimili dati + flowchart/KPI.Ritardi.csv')
set.seed(123)
# Estraggo CTCLE-PACLE
tratte <- unique(dataset$Tratta)
CTCLE_PACLE.data <- subset(dataset, Tratta %in% c("CTCLE-PACLE-1", "CTCLE-PACLE-10", "CTCLE-PACLE-11",
"CTCLE-PACLE-12", "CTCLE-PACLE-13", "CTCLE-PACLE-14",
"CTCLE-PACLE-15", "CTCLE-PACLE-16", "CTCLE-PACLE-17",
"CTCLE-PACLE-2", "CTCLE-PACLE-3", "CTCLE-PACLE-4",
"CTCLE-PACLE-5", "CTCLE-PACLE-6", "CTCLE-PACLE-7",
"CTCLE-PACLE-8", "CTCLE-PACLE-9"))
library('dplyr')
CTCLE_PACLE.data <- CTCLE_PACLE.data %>% arrange(Tratta)
# Compute the silhouette score resulting from dbscan clustering
dbs <- dbscan(CTCLE_PACLE.data[,5:7], eps, minPts) # Run dbscan
library(dbscan)
# Compute the silhouette score resulting from dbscan clustering
dbs <- dbscan(CTCLE_PACLE.data[,5:7], eps, minPts) # Run dbscan
dbs <- dbscan(CTCLE_PACLE.data[,5:7], eps = 0.05, minPts = 3)
dbs
# How to choose eps from minPts?
# Plot of the distances to the minPts nearest neighbor
# dataset dataframe o oggeto di tipo dist
kNNdistplot(CTCLE_PACLE.data[,5:7], k = 3) # The kNN distance is defined as the distance from a point to its k nearest neighbor
# Taking eps = 0.05 seems to be a good threshold
# TUTTI I PUNTI SOTTO RETTA SONP CONDIDERATI CORE POINTS
abline(h = 0.05, col = "red", lty = 2)
# Taking eps = 0.05 seems to be a good threshold
# TUTTI I PUNTI SOTTO RETTA SONP CONDIDERATI CORE POINTS
abline(h = 10, col = "red", lty = 2)
# Taking eps = 0.05 seems to be a good threshold
# TUTTI I PUNTI SOTTO RETTA SONP CONDIDERATI CORE POINTS
abline(h = 7, col = "red", lty = 2)
dbs <- dbscan(dataset, eps =7, minPts = 3)
dbs <- dbscan(CTCLE_PACLE.data[,5:7], eps =7, minPts = 3)
dbs
# How to choose eps from minPts?
# Plot of the distances to the minPts nearest neighbor
# dataset dataframe o oggeto di tipo dist
kNNdistplot(CTCLE_PACLE.data[,5:7], k = 10) # The kNN distance is defined as the distance from a point to its k nearest neighbor
# Run the dbscan
#x dataframe o oggeto di tipo dist
dbs <- dbscan(CTCLE_PACLE.data[,5:7], eps =7, minPts = 3)
abline(h = 7, col = "red", lty = 2) # dist 7 sembra ok
dbs <- dbscan(CTCLE_PACLE.data[,5:7], eps =10, minPts = 10)
dbs
# Plot of the resulting clustering
plot(dataset, col = dbs$cluster + 1L, pch=19)
d <- dist(CTCLE_PACLE.data[,5:7])
new <- cmdscale(d, k=2)
plot(new, col = dbs$cluster + 1L, pch=19)
dbs <- dbscan(CTCLE_PACLE.data[,5:7], eps = 15, minPts = 10)
dbs
dbs <- dbscan(CTCLE_PACLE.data[,5:7], eps = 12, minPts = 10)
dbs
d <- dist(CTCLE_PACLE.data[,5:7])
new <- cmdscale(d, k=2)
plot(new, col = dbs$cluster + 1L, pch=19)
dbs <- dbscan(CTCLE_PACLE.data[,5:7], eps = 10, minPts = 10)
dbs
d <- dist(CTCLE_PACLE.data[,5:7])
new <- cmdscale(d, k=2)
plot(new, col = dbs$cluster + 1L, pch=19)
dataset <- read.csv('../../Dataset/Facsimili dati + flowchart/KPI.Ritardi.csv')
set.seed(123)
# Estraggo CTCLE-PACLE
tratte <- unique(dataset$Tratta)
CTCLE_PACLE.data <- subset(dataset, Tratta %in% c("CTCLE-PACLE-1", "CTCLE-PACLE-10", "CTCLE-PACLE-11",
"CTCLE-PACLE-12", "CTCLE-PACLE-13", "CTCLE-PACLE-14",
"CTCLE-PACLE-15", "CTCLE-PACLE-16", "CTCLE-PACLE-17",
"CTCLE-PACLE-2", "CTCLE-PACLE-3", "CTCLE-PACLE-4",
"CTCLE-PACLE-5", "CTCLE-PACLE-6", "CTCLE-PACLE-7",
"CTCLE-PACLE-8", "CTCLE-PACLE-9"))
library('dplyr')
CTCLE_PACLE.data <- CTCLE_PACLE.data %>% arrange(Tratta)
library(mvtnorm)
library(MVN)
library(rgl)
library(car)
library(dbscan)
library(cluster)
library(fields)
minPts_grid <- c(10, 20, 25, 30, 40)
eps_grid <- c(10, 25, 25,30, 35)
max_share_noise <- 0.2
n <- nrow(CTCLE_PACLE.data)
sil_score <- function(labels, dist) {
# Compute the average of the silhouette widths
sil <- silhouette(labels, dist)
sil_widths <- sil[,"sil_width"]
mean(sil_widths)
}
dbscan_perf <- function(minPts, eps) {
# Compute the silhouette score resulting from dbscan clustering
dbs <- dbscan(dataset, eps, minPts) # Run dbscan
clustered_index <- which(dbs$cluster != 0) # Index of non noise points
#clustered_points <- dataset[clustered_index] # only clustered points
# se ho dataframe
clustered_points <- dataset[clustered_index,] # only clustered points
clustered_labels <- dbs$cluster[clustered_index] # corresponding labels
nb_clusters <- length(unique(clustered_labels))
if ((nb_clusters > 1 & nb_clusters < n) & (length(which(dbs$cluster == 0))/n < max_share_noise)) {
# Silhouette score is defined only if 2 <= nb_clusters <= n-1
sil_score(clustered_labels, dist(clustered_points))
}
else {
# otherwise we return 0 which would be the approx. value of the silhouette
# score if the clusters were completely overlapping
0
}
}
# We compute the silhouette score for all combinations of minPts and eps
perf_grid <- outer(minPts_grid, eps_grid, FUN = Vectorize(dbscan_perf))
dbscan_perf <- function(minPts, eps) {
# Compute the silhouette score resulting from dbscan clustering
dbs <- dbscan(CTCLE_PACLE.data[,5:7], eps, minPts) # Run dbscan
clustered_index <- which(dbs$cluster != 0) # Index of non noise points
#clustered_points <- dataset[clustered_index] # only clustered points
# se ho dataframe
clustered_points <- CTCLE_PACLE.data[,5:7][clustered_index,] # only clustered points
clustered_labels <- dbs$cluster[clustered_index] # corresponding labels
nb_clusters <- length(unique(clustered_labels))
if ((nb_clusters > 1 & nb_clusters < n) & (length(which(dbs$cluster == 0))/n < max_share_noise)) {
# Silhouette score is defined only if 2 <= nb_clusters <= n-1
sil_score(clustered_labels, dist(clustered_points))
}
else {
# otherwise we return 0 which would be the approx. value of the silhouette
# score if the clusters were completely overlapping
0
}
}
# We compute the silhouette score for all combinations of minPts and eps
perf_grid <- outer(minPts_grid, eps_grid, FUN = Vectorize(dbscan_perf))
dimnames(perf_grid) <- list(minPts_grid, eps_grid)
# Histogram of the Silhouette scores
windows()
hist(perf_grid, breaks = 20, xlab = "Silhouette score", xlim = c(-1, 1), main = NULL)
max_score <- max(perf_grid)
min_score <- min(perf_grid)
max_abs <- max(abs(max_score), abs(min_score))
windows(height = 6.5, width = 6.5)
image.plot(x = eps_grid, y = minPts_grid, z = perf_grid, xlab = "eps", ylab = "minPts",
main = 'Silhouette score', col = hcl.colors(64, palette = 'Blue-Red'),
breaks = c(seq(-max_abs, 0, length=33)[-33], seq(0, max_abs, length=33)))
eps_grid <- c(10, 25, 26,30, 35)
windows(height = 6.5, width = 6.5)
image.plot(x = eps_grid, y = minPts_grid, z = perf_grid, xlab = "eps", ylab = "minPts",
main = 'Silhouette score', col = hcl.colors(64, palette = 'Blue-Red'),
breaks = c(seq(-max_abs, 0, length=33)[-33], seq(0, max_abs, length=33)))
# Retrieve best parameter values
max_score <- max(perf_grid)
argmax_score <- which(perf_grid == max_score, arr.ind = TRUE)
best_eps <- eps_grid[argmax_score[2]]
best_minPts <- minPts_grid[argmax_score[1]]
best_eps
best_minPts
max_score
dbs <- dbscan(CTCLE_PACLE.data[,5:7], best_eps, best_minPts)
dbs
minPts_grid <- 10:40
eps_grid <- seq(5, 35, by = 5)
length(eps_grid)
eps_grid <- seq(5, 35, by = 1)
kNNdistplot(CTCLE_PACLE.data[,5:7], k = 10) # The kNN distance is defined as the distance from a point to its k nearest neighbor
abline(h = 5, col = "red", lty = 2) # dist 7 sembra ok
kNNdistplot(CTCLE_PACLE.data[,5:7], k = 10) # The kNN distance is defined as the distance from a point to its k nearest neighbor
abline(h = 5, col = "red", lty = 2) # dist 7 sembra ok
kNNdistplot(CTCLE_PACLE.data[,5:7], k = 10) # The kNN distance is defined as the distance from a point to its k nearest neighbor
abline(h = 7, col = "red", lty = 2) # dist 7 sembra ok
kNNdistplot(CTCLE_PACLE.data[,5:7], k = 40) # The kNN distance is defined as the distance from a point to its k nearest neighbor
abline(h = 35, col = "red", lty = 2) # dist 7 sembra ok
minPts_grid <- 10:40
eps_grid <- seq(7, 35, by = 1)
kNNdistplot(CTCLE_PACLE.data[,5:7], k = 40) # The kNN distance is defined as the distance from a point to its k nearest neighbor
abline(h = 37, col = "red", lty = 2)
minPts_grid <- 10:40
eps_grid <- seq(7, 37, by = 1)
perf_grid <- outer(minPts_grid, eps_grid, FUN = Vectorize(dbscan_perf))
dimnames(perf_grid) <- list(minPts_grid, eps_grid)
# Histogram of the Silhouette scores
windows()
hist(perf_grid, breaks = 20, xlab = "Silhouette score", xlim = c(-1, 1), main = NULL)
hist(perf_grid, breaks = 31, xlab = "Silhouette score", xlim = c(-1, 1), main = NULL)
hist(perf_grid, breaks = 20, xlab = "Silhouette score", xlim = c(-1, 1), main = NULL)
max_score <- max(perf_grid)
min_score <- min(perf_grid)
max_abs <- max(abs(max_score), abs(min_score))
windows(height = 6.5, width = 6.5)
image.plot(x = eps_grid, y = minPts_grid, z = perf_grid, xlab = "eps", ylab = "minPts",
main = 'Silhouette score', col = hcl.colors(64, palette = 'Blue-Red'),
breaks = c(seq(-max_abs, 0, length=33)[-33], seq(0, max_abs, length=33)))
max_score <- max(perf_grid)
argmax_score <- which(perf_grid == max_score, arr.ind = TRUE)
best_eps <- eps_grid[argmax_score[2]]
best_minPts <- minPts_grid[argmax_score[1]]
best_eps
best_minPts
max_score
dbs <- dbscan(CTCLE_PACLE.data[,5:7], best_eps, best_minPts)
dbs
windows()
plot(dataset, col = dbs$cluster + 1L, pch=19)
windows()
plot(CTCLE_PACLE.data[,5:7], col = dbs$cluster + 1L, pch=19)
d <- dist(CTCLE_PACLE.data[,5:7])
new <- cmdscale(d, k=2)
plot(new, col = dbs$cluster + 1L, pch=19)
day_of_week = CTCLE_PACLE.data[,3]
#numero di osservazioni divise per clusters e tipologia
cont_table = table(day_of_week)
cont_table
# percentuali delle osservazioni in ogni clusters calcolate sul totale
cont_table_perc_tot= prop.table(cont_table)
cont_table_perc_tot
# percentuali calcolate sull'unico cluster
cont_table_perc= prop.table(cont_table, margin = 2)
cat_cluster$cluster = as.factor(dbs$cluster)
cat_cluster = categorical
cat_cluster = CTCLE_PACLE.data[,3]
cat_cluster$cluster = as.factor(dbs$cluster)
cat_cluster$cluste
cat_cluster
day_of_week = cat_cluster
#numero di osservazioni divise per clusters e tipologia
cont_table = table(day_of_week)
day_of_week = cat_cluster[ , c(1,ncol(cat_cluster))]
cat_cluster
day_of_week
day_of_week = cat_cluster[ , c(1,ncol(cat_cluster))]
day_of_week = cat_cluster[ , 1]
cat_cluster
cat_cluster = CTCLE_PACLE.data[,3]
cat_cluster$cluster = as.factor(dbs$cluster)
cat_cluster = as.data.frame(CTCLE_PACLE.data[,3])
View(cat_cluster)
cat_cluster = as.data.frame(day_of_week = CTCLE_PACLE.data[,3])
View(CTCLE_PACLE.data)
View(cat_cluster)
cat_cluster = data.frame(day_of_week = CTCLE_PACLE.data[,3])
View(cat_cluster)
cat_cluster$cluster = as.factor(dbs$cluster)
day_of_week = cat_cluster[, c(1, ncol(cat_cluster))]
day_of_week
cat_cluster = data.frame(day =CTCLE_PACLE.data[,2],  day_of_week = CTCLE_PACLE.data[,3])
cat_cluster$cluster = as.factor(dbs$cluster)
subset_day_of_week = cat_cluster[, c(2, ncol(cat_cluster))]
#numero di osservazioni divise per clusters e tipologia
cont_table = table(subset_day_of_week)
cont_table
# percentuali delle osservazioni in ogni clusters calcolate sul totale
cont_table_perc_tot= prop.table(cont_table)
# percentuali calcolate sull'unico cluster
cont_table_perc= prop.table(cont_table, margin = 2)
# ex nel cluster 1 il 63% degli employee che fanno parte del cluster 1 fa parte del gruppo Travel_Rarely
cont_table
cont_table_perc_tot
cont_table_perc
balloonplot(t(cont_table), main ="Day of the Week by Cluster", xlab ="Cluster",ylab="Day of the Week",
label = FALSE, show.margins = FALSE)
library(GDAtools) # Computation of 'Burt Table'
install.packages('GDAtools')
balloonplot(t(cont_table), main ="Day of the Week by Cluster", xlab ="Cluster",ylab="Day of the Week",
label = FALSE, show.margins = FALSE)
library('gplots')
library(gplots)
install.packages('gplots ')
library(gplots)
install.packages("gplots")
library(gplots)
balloonplot(t(cont_table), main ="Day of the Week by Cluster", xlab ="Cluster",ylab="Day of the Week",
label = FALSE, show.margins = FALSE)
result.k <- kmeans(CTCLE_PACLE.data[,5:7], centers=3) # Centers: fixed number of clusters
sil <- silhouette(clustered_labels, dist(clustered_points))
library(cluster)
clustered_points <- CTCLE_PACLE.data[,5:7] # only clustered points
clustered_labels <- result.k$cluster # labels of clusters
sil <- silhouette(clustered_labels, dist(clustered_points))
summary(sil)
sil_score <- function(labels, dist) {
# Compute the average of the silhouette widths
sil <- silhouette(labels, dist)
sil_widths <- sil[,"sil_width"]
mean(sil_widths)
}
sil_score(clustered_labels, dist(clustered_points))
## Plot Numeric Data by Cluster
numeric = CTCLE_PACLE.data[,5:7]
numeric$cluster = as.factor(dbs$cluster)
View(numeric)
#ibm_numeric_subset = ibm_numeric_subset %>% filter(cluster!=0)
#medie calcolate divise per clusters
numeric_mean = numeric %>% group_by(cluster) %>% summarize_all(mean)
# medie scalate divise per clusters
numeric_mean_scaled = numeric_mean[,-1] %>% as.matrix() %>% scale() %>% data.frame()
numeric_mean_scaled$cluster = numeric_mean$cluster
long_numeric_mean = melt(numeric_mean_scaled,id.vars="cluster")
# Select Some Numeric Variables
library(reshape)
long_numeric_mean = melt(numeric_mean_scaled,id.vars="cluster")
ggplot(long_numeric_mean,aes(x=variable,y=value,fill=cluster))+ geom_bar(stat="identity",position = position_dodge(0.75), width = 0.5) + xlab("Variable")+ylab("Normalized Mean Score") + coord_flip()
library('ggplot2')
ggplot(long_numeric_mean,aes(x=variable,y=value,fill=cluster))+ geom_bar(stat="identity",position = position_dodge(0.75), width = 0.5) + xlab("Variable")+ylab("Normalized Mean Score") + coord_flip()
long_numeric_mean = melt(numeric_mean,id.vars="cluster")
numeric_mean
long_numeric_mean = melt(numeric_mean_scaled,id.vars="cluster")
ggplot(numeric_mean,aes(x=variable,y=value,fill=cluster))+ geom_bar(stat="identity",position = position_dodge(0.75), width = 0.5) + xlab("Variable")+ylab("Normalized Mean Score") + coord_flip()
long_numeric_mean
numeric_mean_scaled = numeric_mean[,-1] %>% as.matrix() %>% scale() %>% data.frame()
numeric_mean_scaled$cluster = numeric_mean$cluster
numeric_mean_scaled
numeric_mean
data.frame(numeric_mean)
long_numeric_mean = melt(data.frame(numeric_mean),id.vars="cluster")
ggplot(long_numeric_mean,aes(x=variable,y=value,fill=cluster))+ geom_bar(stat="identity",position = position_dodge(0.75), width = 0.5) + xlab("Variable")+ylab("Normalized Mean Score") + coord_flip()
long_numeric_mean = melt(numeric_mean_scaled,id.vars="cluster")
ggplot(long_numeric_mean,aes(x=variable,y=value,fill=cluster))+ geom_bar(stat="identity",position = position_dodge(0.75), width = 0.5) + xlab("Variable")+ylab("Normalized Mean Score") + coord_flip()
ggplot(data.frame(numeric_mean),aes(x=variable,y=value,fill=cluster))+ geom_bar(stat="identity",position = position_dodge(0.75), width = 0.5) + xlab("Variable")+ylab("Mean Score") + coord_flip()
long_numeric_mean = melt(data.frame(numeric_mean),id.vars="cluster")
ggplot(long_numeric_mean,aes(x=variable,y=value,fill=cluster))+ geom_bar(stat="identity",position = position_dodge(0.75), width = 0.5) + xlab("Variable")+ylab("Mean Score") + coord_flip()
ggplot(long_numeric_mean,aes(x=variable,y=value,fill=cluster))+ geom_bar(stat="identity",position = position_dodge(0.75), width = 0.5) + xlab("Variable")+ylab("Normalized Mean Score") + coord_flip()
long_numeric_mean = melt(numeric_mean_scaled,id.vars="cluster")
x11()
ggplot(long_numeric_mean,aes(x=variable,y=value,fill=cluster))+ geom_bar(stat="identity",position = position_dodge(0.75), width = 0.5) + xlab("Variable")+ylab("Normalized Mean Score") + coord_flip()
numeric_mean
dbs$cluster
dbs
d <- dist(CTCLE_PACLE.data[,5:7])
new <- cmdscale(d, k=2)
plot(new, col = dbs$cluster + 1L, pch=19)
result.k <- kmeans(CTCLE_PACLE.data[,5:7], centers=3) # Centers: fixed number of clusters
result.k$size         # dimension of the clusters
# Plot w/Day
x11()
subset_day = cat_cluster[, c(1, ncol(cat_cluster))]
#numero di osservazioni divise per clusters e tipologia
cont_table = table(subset_day)
# percentuali delle osservazioni in ogni clusters calcolate sul totale
cont_table_perc_tot= prop.table(cont_table) # percentuali cacolate su intero dataset
# percentuali calcolate sull'unico cluster
cont_table_perc= prop.table(cont_table, margin = 2) # percentuali cacolate su cluster
cont_table
cont_table_perc_tot
cont_table_perc
library(gplots)
balloonplot(t(cont_table), main ="Day Cluster", xlab ="Cluster",ylab="Day",
label = FALSE, show.margins = FALSE)
balloonplot(t(cont_table), main ="Day Cluster", xlab ="Cluster",ylab="Day",
label = FALSE, show.margins = FALSE, dot.size = 2, dot.col = "salmon" )
balloonplot(t(cont_table), main ="Day Cluster", xlab ="Cluster",ylab="Day",
label = FALSE, show.margins = FALSE, dot.col = "salmon" )
balloonplot(t(cont_table), main ="Day Cluster", xlab ="Cluster",ylab="Day",
label = FALSE, show.margins = FALSE, dotchar=19, dotcolor="salmon")
balloonplot(t(cont_table), main ="Day Cluster", xlab ="Cluster",ylab="Day",
label = FALSE, show.margins = FALSE, dotchar=20, dotcolor="salmon")
balloonplot(t(cont_table), main ="Day of the Week by Cluster", xlab ="Cluster",ylab="Day of the Week",
label = FALSE, show.margins = FALSE, dotchar=20, dotcolor="salmon")
x11()
subset_day_of_week = cat_cluster[, c(2, ncol(cat_cluster))]
#numero di osservazioni divise per clusters e tipologia
cont_table = table(subset_day_of_week)
# percentuali delle osservazioni in ogni clusters calcolate sul totale
cont_table_perc_tot= prop.table(cont_table) # percentuali cacolate su intero dataset
# percentuali calcolate sull'unico cluster
cont_table_perc= prop.table(cont_table, margin = 2) # percentuali cacolate su cluster
cont_table
cont_table_perc_tot
cont_table_perc
library(gplots)
balloonplot(t(cont_table), main ="Day of the Week by Cluster", xlab ="Cluster",ylab="Day of the Week",
label = FALSE, show.margins = FALSE, dotchar=20, dotcolor="salmon")
# Caricamento del dataset e delle funzioni
dataset <- read.csv('../../Dataset/Facsimili dati + flowchart/KPI.Ritardi.csv')
set.seed(123)
# Estraggo CTCLE-PACLE
tratte <- unique(dataset$Tratta)
CTCLE_PACLE.data <- subset(dataset, Tratta %in% c("CTCLE-PACLE-1", "CTCLE-PACLE-10", "CTCLE-PACLE-11",
"CTCLE-PACLE-12", "CTCLE-PACLE-13", "CTCLE-PACLE-14",
"CTCLE-PACLE-15", "CTCLE-PACLE-16", "CTCLE-PACLE-17",
"CTCLE-PACLE-2", "CTCLE-PACLE-3", "CTCLE-PACLE-4",
"CTCLE-PACLE-5", "CTCLE-PACLE-6", "CTCLE-PACLE-7",
"CTCLE-PACLE-8", "CTCLE-PACLE-9"))
index <- which(dataset$Tratta %in% c("CTCLE-PACLE-1", "CTCLE-PACLE-10", "CTCLE-PACLE-11",
"CTCLE-PACLE-12", "CTCLE-PACLE-13", "CTCLE-PACLE-14",
"CTCLE-PACLE-15", "CTCLE-PACLE-16", "CTCLE-PACLE-17",
"CTCLE-PACLE-2", "CTCLE-PACLE-3", "CTCLE-PACLE-4",
"CTCLE-PACLE-5", "CTCLE-PACLE-6", "CTCLE-PACLE-7",
"CTCLE-PACLE-8", "CTCLE-PACLE-9"))
library('dplyr')
CTCLE_PACLE.data <- CTCLE_PACLE.data %>% arrange(Tratta)
View(dataset)
View(CTCLE_PACLE.data)
library(MASS)
library(car)
library(rgl)
library(glmnet)
unique(as.factor(CTCLE_PACLE.data$Orario.Par))
n_dummy = 1 - unique(as.factor(CTCLE_PACLE.data$Orario.Par))
n_dummy = length(unique(as.factor(CTCLE_PACLE.data$Orario.Par)))-1
names(CTCLE_PACLE.data)
Creating dummy variables in R is a common task when dealing with categorical data in statistical modeling. Dummy variables (also known as indicator variables) are binary (0/1) variables that indicate the presence of a particular category. Here's a step-by-step guide on how to create dummy variables in R:
install.packages("fastDummies")
library(fastDummies)
dummy_df <- dummy_cols(CTCLE_PACLE.data, select_columns = "Orario.Par", remove_first_dummy = TRUE)
View(dummy_df)
fit <- lm(Ritardo ~ dummy_df[,8:23], data = CTCLE_PACLE.data)
selected_columns <- names(dummy_df)[8:23]
formula <- as.formula(paste("Ritardo ~", paste(selected_columns, collapse = " + ")))
formula
fit <- lm(formula, data = dummy_df)
selected_columns
paste(selected_columns, collapse = " + ")
formula <- as.formula(paste("Ritardo ~", paste(selected_columns, collapse = " + ")))
formula
selected_columns <- make.names(dummy_df)[8:23]
selected_columns
selected_columns <- names(dummy_df)[8:23]
sanitized_columns <- make.names(selected_columns)
sanitized_columns
formula <- as.formula(paste("Ritardo ~", paste(selected_columns, collapse = " + ")))
formula
paste(selected_columns, collapse = " + ")
fit <- lm(Ritardo ~ paste(selected_columns, collapse = " + "),  data = dummy_df)
paste(selected_columns, collapse = " + ")
names_col <-
fit <- lm(Ritardo ~ selected_columns,  data = dummy_df)
selected_columns
selected_columns <- strsplit(selected_columns, " \\+ ")[[1]]
selected_columns
selected_columns <- names(dummy_df)[8:23]
selected_columns <- paste(selected_columns, collapse = " + ")
selected_columns <- strsplit(selected_columns, " \\+ ")[[1]]
selected_columns
dummy_df <- model.matrix(~ CTCLE_PACLE.data$Orario.Par - 1, data = df)
dummy_df <- model.matrix(~ as.matrix(CTCLE_PACLE.data$Orario.Par) - 1, data = df)
as.matrix(CTCLE_PACLE.data$Orario.Par)
dummy_df <- model.matrix(~ Orario.Par - 1, data = CTCLE_PACLE.data)
dummy_df
fit <- lm(Ritardo ~ dummy_df,  data = CTCLE_PACLE.data)
dummy_orario <- model.matrix(~ Orario.Par - 1, data = CTCLE_PACLE.data)
fit <- lm(Ritardo ~ dummy_orario,  data = CTCLE_PACLE.data)
summary(fit)
data <- read.csv('df_shuffled.csv')
setwd("C:/Users/feder/Documents/GitHub/qda-project/R code")
data <- read.csv('df_shuffled.csv')
data <- read.csv2('df_shuffled.csv')
data <- read.csv2('df_shuffled.csv', sep = ';')
data <- read.csv2('df_shuffled.csv', sep = ':')
data <- read.csv('df_shuffled.csv', sep = ':')
data <- read.csv('df_shuffled.csv', sep = ';')
data <- read.csv('df_shuffled.csv', sep = '\t')
View(data)
