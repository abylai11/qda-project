{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">Quality Data Analysis - Project Work [FULL PROJECT] </span>\n",
    "## Team 1\n",
    "\n",
    "### Course Details:\n",
    "- Academic Year: 2023-2024\n",
    "\n",
    "### Project Details:\n",
    "- Title: [ENTER PROJECT TITLE HERE]\n",
    "\n",
    "### Team Members:\n",
    "- Abylaikhan Orynbassar\n",
    "- Giulia Mezzadri\n",
    "- Federico Angelo Mor\n",
    "- Federica Rena\n",
    "\n",
    "### Instructor:\n",
    "- Panagiotis Tsiamyrtzis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "- This is a template notebook for the project work.\n",
    "- Please fill in the details above (team members, instructor, etc.)\n",
    "## PHASE 1 - Report structure\n",
    "Please use the following sections for your project report:\n",
    "- **Introduction** [max 3500 characters including spaces]\n",
    "    - Recap the project work framework and objective\n",
    "    - Briefly summarize the overall methodology you used to model and analyse your data\n",
    "    - Briefly summarize the state-of-the-art you analysed to support your study (if any).\n",
    "- **Assumptions and preliminary data analysis** [max 5000 characters including spaces]\n",
    "    - Clearly state and motivate all the assumptions your proposed methodology relies on; present and discuss any preliminary data analysis and visualization you applied on the data.\n",
    "- **Proposed methodology** [max 10000 characters including spaces]\n",
    "    - Synthetically describe, motivate and critically discuss your proposed statistical process monitoring approach. \n",
    "- **Results** [max 10000 characters including spaces]\n",
    "    - Synthetically presents and discuss the results of your statistical process monitoring design. \n",
    "\n",
    "## PHASE 2 - Report structure\n",
    "Please use the following sections for your project report:\n",
    "- **Preliminary data analysis** [max 5000 characters including spaces]\n",
    "    - Synthetically describe and discuss any preliminary data analysis and visualization applied on the new dataset.\n",
    "- **Test of your proposed approach on new data** [max 5000 characters including spaces]\n",
    "    - Synthetically presents and discuss the results you got applying to the new data your previously designed statistical process monitoring approach.\n",
    "- **Discussion** [max 5000 characters including spaces]\n",
    "    - Critically discuss your results In this Section you can also propose possible ways to tune or revise your previously designed method to enhance its defect detection performance. \n",
    "\n",
    "You can add code cells to any of the above sections to show your code or display images. Each block of code should be accompanied by a brief description of what it does (not counted in characters limits).\n",
    "\n",
    "## Submission\n",
    "- Name your notebook as `teamXX.ipynb` where `XX` is your team number.\n",
    "- Submit your notebook together with the Dataframe as a ZIP file on Webeep by the deadline. The ZIP file name must clearly state the \"TEAM NUMBER\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 1 ------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "<!-- i am adding numbers to titles so is tidier i think -->\n",
    "\n",
    "<!-- - Recap the project work framework and objective\n",
    "- Briefly summarize the overall methodology you used to model and analyse your data\n",
    "- Briefly summarize the state-of-the-art you analysed to support your study (if any). -->\n",
    "\n",
    "The overall procedure can be summarized as follows:\n",
    "- Dataset creation and refinement [section 2](#2.-Assumptions-and-preliminary-data-analysis)\n",
    "- Variables definition and selection [section 3](#3.-Proposed-methodology)\n",
    "- Control charting [section 3](#3.-Proposed-methodology)\n",
    "\n",
    "where each point will be further detailed in the next sections (as linked trough the square brackets)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Assumptions and preliminary data analysis\n",
    "<!-- - Clearly state and motivate all the assumptions your proposed methodology relies on; present and discuss any preliminary data analysis and visualization you applied on the data. -->\n",
    "Assumptions: later we check normality, but at the beginning we did not check anything special.\n",
    "\n",
    "### Data analysis\n",
    "After the image acquisition, we ran the provided python script to generate all the images statistics (e.g. Area, Perimeter, Eccentricity, etc). At that stage the unique \"key\" which identified each object was the combination of the Image Name and Position variables, so we decided to merge them into a single ID using this simple function (of which the inverse function, to recover Image Name and Position given the created ID, could also be easily defined):\n",
    "```python\n",
    "def img_info_to_part_id(imgname, location):\n",
    "\timgid = int(re.search(r\"img(\\d+)\\.bmp\", imgname).group(1))\n",
    "\tif location == \"top_left\":\n",
    "\t\treturn (imgid - 1) * 4\n",
    "\telif location == \"bottom_left\":\n",
    "\t\treturn (imgid - 1) * 4 + 1\n",
    "\telif location == \"top_right\":\n",
    "\t\treturn (imgid - 1) * 4 + 2\n",
    "\telif location == \"bottom_right\":\n",
    "\t\treturn (imgid - 1) * 4 + 3\n",
    "\telse:\n",
    "\t\traise ValueError(\"Invalid location: {}\".format(location))\n",
    "\n",
    "# img_info_to_part_id(\"img01.bmp\", \"top_left\")     -> 0\n",
    "# img_info_to_part_id(\"img01.bmp\", \"bottom_left\")  -> 1\n",
    "# img_info_to_part_id(\"img01.bmp\", \"top_right\")    -> 2\n",
    "# img_info_to_part_id(\"img01.bmp\", \"bottom_right\") -> 3\n",
    "# img_info_to_part_id(\"img02.bmp\", \"top_left\")     -> 4\n",
    "# img_info_to_part_id(\"img02.bmp\", \"bottom_left\")  -> 5\n",
    "# img_info_to_part_id(\"img02.bmp\", \"top_right\")    -> 6\n",
    "# img_info_to_part_id(\"img02.bmp\", \"bottom_right\") -> 7\n",
    "```\n",
    "\n",
    "The script also provided a segmentation part which automatically isolated the single objects, by cropping a region around them. However, soon after we decided to implement our own code to do the segmentation, since we thought that to compare more fairly the images statistics we needed a \"common ground\" on which they should be computed. That is, we thought that we should firstly center the objects and crop them around their main outer edge, and only then compute their statistics. Otherwise we believed that the values some possibly relevant variable, such as the Perimeter or the Axes Lengths, would have been altered by the wrong orientation of the original images. In this way instead we brough all the object images to the same context (perfect centering alignement and perfect cropping), so that the later comparison of their characteristics would be more accurate.\\\n",
    "To do this we wrote the following function\n",
    "\n",
    "```python\n",
    "def rotate_and_crop(img, rect, verbose=0):\n",
    "\t# get params\n",
    "\tcenter, size, angle = rect[0], rect[1], rect[2]\n",
    "\t\n",
    "\tif angle > 45: # angle correction\n",
    "\t\tangle = angle - 90\n",
    "\tif verbose == 1: # debug information\n",
    "\t\tprint(f\"Angle inside function is {angle}\")\n",
    "\t\n",
    "\tcenter, size = tuple(map(int, center)), tuple(map(int, size))\n",
    "\t# get row and col num in img\n",
    "\theight, width = img.shape[0], img.shape[1]\n",
    "\t# rotation matrix\n",
    "\tM = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "\t# apply rotation\n",
    "\timg_rot = cv2.warpAffine(img, M, (width, height))\n",
    "\t# crop it\n",
    "\timg_crop = cv2.getRectSubPix(img_rot, size, center)\n",
    "\treturn img_crop, img_rot\n",
    "```\n",
    "\n",
    "which we applied in the final procedure of the new dataset definition. This procedure involved the following steps: ecc "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Proposed methodology"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References (if any)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 2 -----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of your proposed approach on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qda_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
